{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#what-is-rose","title":"What is ROSE? \ud83c\udf39","text":"<p>ROSE: RADICAL Orchestrator for Surrogate Exploration (ROSE) toolkit is a framework designed to enable the concurrent and adaptive execution of simulation, surrogate training, and selection tasks on High-Performance Computing (HPC) resources. ROSE is a Python package that provides tools for developing active and reinforcement learning (AL and RL) methods for scientific applications. It enables users to define simulation and surrogate training tasks and automatically manage their execution on HPC resources via a predefined set of Learning Policies (Learners).</p> <p>ROSE also includes tools to facilitate the selection of the most effective surrogate model for a given simulation based on performance metrics.</p> <p>ROSE leverages RADICAL-Cybertools, a set of middleware building blocks that simplify the development of sophisticated scientific workflows on HPC resources.</p>"},{"location":"#why-rose","title":"Why ROSE? \ud83d\ude80\ud83d\ude80\ud83d\ude80","text":"<p>ROSE allows you to enable, scale, and accelerate your learning workflows across thousands of CPU cores and GPUs effectively and efficiently with just a few lines of code. ROSE is built on the RADICAL-AsyncFlow and RADICAL-Pilot runtime system, a powerful execution engine that enables the distributed execution of millions of scientific tasks and applications such as executables, functions and containers effortlessly.</p> ROSE Mind Map and Flow Diagram"},{"location":"#key-features","title":"Key Features \u2b50\u2b50\u2b50","text":"<ul> <li>Express, build and run different surrogate building workflows on HPC such as Active, and Reinforcement Learning workflows in minutes.</li> <li> <p>Seamless Execution of Complex ML surrogate building Workflows on HPC across diverse computing platforms:</p> <ul> <li>Local desktops and laptops</li> <li>Local and remote clusters and grids</li> <li>Leadership-class HPC platforms</li> </ul> </li> <li> <p>Asynchronous, Flexible Workflow Management capabilities</p> </li> <li> <p>Pythonic API providing a clean separation between the learning workflow components:</p> <ul> <li>Simulation</li> <li>Training</li> <li>Conditional ML metrics</li> <li>Multiple out of the box learning policies (learners)</li> </ul> </li> <li> <p>Heterogeneous Task Execution on GPUs, CPUs, with MPI and/or sequential tasks.</p> </li> </ul> NSF Funded Project (#2212550)"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#changelog","title":"Changelog","text":"<p>All notable changes to the ROSE project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#unreleased","title":"[Unreleased]","text":""},{"location":"changelog/#020-2026-02-27","title":"[0.2.0] - 2026-02-27","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>RHAPSODY backend integration: Execution backends (<code>RadicalExecutionBackend</code>, <code>ConcurrentExecutionBackend</code>) are now imported from <code>rhapsody-py</code> (<code>from rhapsody.backends import ...</code>) instead of <code>radical.asyncflow</code>. <code>WorkflowEngine</code> remains in <code>radical.asyncflow</code>. Updated all examples, tutorials, docs, and notebooks accordingly.</li> <li>Pre-commit hooks: Added <code>.pre-commit-config.yaml</code> with docformatter, ruff, standard file checks, actionlint, GitHub workflow validation, and typos. The <code>examples/use_cases/</code> directory is excluded from linting.</li> <li>CI pre-commit gate: The <code>tests.yml</code> workflow now runs pre-commit as a required job before unit and integration tests, replacing the separate <code>lint</code> job.</li> <li>New tutorials: Added <code>03-highly-parallel-surrogates</code> and <code>04-al-algorithm-selector</code> tutorials with corresponding optional dependencies in <code>tutorials/pyproject.toml</code> and <code>tutorials/README.md</code>.</li> <li>New <code>start()</code> API: Replaced the blocking <code>teach()</code> method with an asynchronous iterator <code>start()</code>. This allows users to instrument the loop, log metrics in real-time (e.g., to MLflow), and implement custom early stopping or adaptive logic.</li> <li>IterationState: Granular state reporting after each iteration, providing metrics, labeled/unlabeled counts, and statistics in a structured dataclass.</li> <li>Dynamic Configuration: Added ability to update learner configuration (batch sizes, task arguments, etc.) between iterations using <code>learner.set_next_config()</code>.</li> <li>MLflow integration: <code>rose.learner()</code> is now compatible with MLflow tracking to support the diffusion model community's need to monitor the training process via ROSE.</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Dependency update: <code>rhapsody-py[radical_pilot]</code> added as a core dependency; Dragon HPC backend (<code>rhapsody-py[dragon]</code>) auto-installed on Python \u22643.12 via PEP 508 environment marker. <code>radical.asyncflow</code> retained for <code>WorkflowEngine</code>.</li> <li>Python support: Minimum Python version is 3.10; Python 3.9 dropped from all tooling, CI, and tox environments.</li> <li>Async-first execution: The core learner logic is now <code>asyncio</code>-based, enabling better concurrency and integration with modern Python stacks.</li> <li>Separation of concerns: Orchestration logic (ROSE) is more clearly separated from task execution (AsyncFlow/RHAPSODY).</li> <li>Package discovery: Explicitly scoped setuptools to the <code>rose</code> package to prevent accidental inclusion of <code>tutorials/</code> and <code>examples/</code> in the distribution.</li> <li>Ruff configuration: Raised line length to 100, added ML naming convention rules to the ignore list (<code>N803</code>, <code>N806</code>, <code>N801</code>, <code>N812</code>\u2013<code>N817</code>), and scoped the <code>B006</code> exception to example <code>run_me.py</code> files where <code>task_description={\"shell\": True}</code> is a required API pattern.</li> <li>GitHub Actions: Fixed unquoted <code>$GITHUB_ENV</code> shell variable in <code>tests.yml</code> and <code>ci.yml</code> (shellcheck SC2086).</li> </ul>"},{"location":"changelog/#deprecated","title":"Deprecated","text":"<ul> <li><code>learner.teach()</code>: This method is deprecated and will be removed in a future version. Users should migrate to the <code>async for state in learner.start()</code> pattern.</li> </ul>"},{"location":"getting-started/dry-run/","title":"2.Dry Run","text":""},{"location":"getting-started/dry-run/#dry-run-with-rose","title":"\ud83e\uddea Dry Run with ROSE","text":"<p>ROSE supports dry runs to help you validate your machine learning surrogate workflows without actually executing simulations or launching jobs on HPC systems. This is useful for debugging workflow structure, verifying task generation, and ensuring that everything is connected properly before committing compute resources.</p>"},{"location":"getting-started/dry-run/#example","title":"Example:","text":"<p>Running a Dry Run with <code>SequentialActiveLearner</code> Below is a minimal example showing how to set up and perform a dry run using the <code>SequentialActiveLearner</code> in ROSE.</p> <pre><code>import os\nimport sys\nimport asyncio\n\nfrom rose.al.active_learner import SequentialActiveLearner\n\nfrom radical.asyncflow import WorkflowEngine\n\n\nasync def rose_al():\n    # Enable dry run in the workflow engine\n    asyncflow = await WorkflowEngine.create(dry_run=True)\n\n    # Create an active learner with the workflow engine\n    acl = SequentialActiveLearner(asyncflow)\n\n    # Path to your training script or code\n    code_path = f'{sys.executable} {os.getcwd()}'\n\n    # Now use `acl` to define and simulate the workflow...\n    # (e.g., acl.run(...), acl.sample(...), etc.)\n    # During dry run, tasks will be logged but not executed.\n</code></pre> <p>Run the async function </p><pre><code>asyncio.run(rose_al())\n</code></pre><p></p>"},{"location":"getting-started/dry-run/#what-happens-in-a-dry-run","title":"\u2705 What Happens in a Dry Run?","text":"<ul> <li> <p>Tasks are created and scheduled, but not actually run.</p> </li> <li> <p>ROSE logs the task definitions, dependencies, and flow structure.</p> </li> <li> <p>Useful for catching configuration errors or invalid paths before real execution.</p> </li> </ul>"},{"location":"getting-started/faq/","title":"3.FAQ","text":""},{"location":"getting-started/faq/#frequently-asked-questions-faq","title":"Frequently Asked Questions (FAQ)","text":""},{"location":"getting-started/faq/#q1-how-do-i-install-rose-on-my-machine","title":"Q1: How do I install ROSE on my machine?","text":"<p>Refer to the Installation Guide for detailed instructions based on your operating system.</p>"},{"location":"getting-started/faq/#q2-what-is-a-dry-run","title":"Q2: What is a dry run?","text":"<p>A dry run allows you to simulate the execution of your tasks locally without making any changes to the behavior of your ML workflow. It's a way to verify your setup is working on HPC before applying it to prevent time and resource waste.</p>"},{"location":"getting-started/faq/#q3-what-if-i-have-an-issue","title":"Q3: What if I have an issue?","text":"<p>If you have any additional questions or an issue, feel free to reach out to our support team by opening a Github ticket.</p>"},{"location":"getting-started/faq/#q4-how-can-i-participate-in-the-development-of-rose","title":"Q4: How can I participate in the development of ROSE?","text":"<p>By following these steps:</p> <ol> <li>Fork the main branch of ROSE</li> <li>Create a new branch in the forked ROSE repo and name it as follows: <code>user_name/feature_x</code>,</li> <li>Open a PR from <code>user_name/feature_x</code> towards <code>ROSE/main</code></li> </ol>"},{"location":"getting-started/installation/","title":"1.Installation","text":""},{"location":"getting-started/installation/#installation","title":"Installation","text":"<p>To get started with the ROSE, you'll first need to install it on your machine or the targeted cluster. Below are the steps to install it on different operating systems. For a full list of the supported HPC machines, please refer to the following link: RADICAL-Pilot Supported HPC Machines</p>"},{"location":"getting-started/installation/#for-linux-and-macos","title":"For Linux and macOS \ud83d\udc27","text":"<ol> <li>Clone the latest version from the official website.    <pre><code>git clone https://github.com/radical-cybertools/ROSE.git\n</code></pre></li> <li>Run the following commands to install ROSE and its dependencies:     <pre><code>cd ROSE\npip install .\n</code></pre></li> </ol>"},{"location":"getting-started/installation/#for-windows-machines","title":"For Windows Machines \ud83d\udda5\ufe0f","text":"<ol> <li>Download the Windows WSL installer from the official website.</li> <li>Setup you WSL user name and password.</li> <li>Make sure you have Python 3.9 or higher in your WSL as follows:     <pre><code>python --version\n</code></pre></li> <li>create new pip virtual env:     <pre><code>python3 -m venv rose_env\n</code></pre></li> <li>Activate the env:    <pre><code>source rose_env/bin/activate\n</code></pre></li> <li>Clone the latest version from the official website.    <pre><code>git clone https://github.com/radical-cybertools/ROSE.git\n</code></pre></li> <li>Run the following commands to install ROSE and its dependencies:     <pre><code>cd ROSE\npip install .\n</code></pre></li> </ol> <p>If you encounter any issues, refer to the Issues Section.</p>"},{"location":"integrations/mlflow/","title":"MLflow","text":""},{"location":"integrations/mlflow/#mlflow-integration","title":"MLflow Integration","text":"<p>This guide demonstrates how to combine ROSE's workflow orchestration with MLflow's experiment tracking to create a robust and observable active learning system.</p>"},{"location":"integrations/mlflow/#overview","title":"Overview","text":"<p>ROSE and MLflow provide a complementary relationship in a research or production pipeline:</p> <ul> <li>ROSE (Orchestration): Manages task execution order, dependencies, high-performance computing (HPC) resources, and the iterative loop.</li> <li>MLflow (Tracking): Records hyperparameters, performance metrics, trained models, and diagnostic plots for analysis and reproducibility.</li> </ul> Tool Role Focus ROSE Orchestrator What runs? When? Where? In what order? MLflow Tracker What happened? How well did it perform? Can I reproduce it?"},{"location":"integrations/mlflow/#installation","title":"Installation","text":"<p>To use this integration, you need both <code>mlflow</code> and <code>ROSE</code> installed in your environment.</p> <pre><code># Install MLflow\npip install mlflow\n\n# Optional: for visualization logic in the example\npip install matplotlib scikit-learn\n</code></pre>"},{"location":"integrations/mlflow/#quick-start","title":"Quick Start","text":"<p>You can find a complete integration example in the codebase at <code>examples/integrations/mlflow/mlflow_rose.py</code>.</p> <pre><code># Run the integration example\npython examples/integrations/mlflow/mlflow_rose.py\n\n# Launch the MLflow UI to view results\nmlflow ui --port 5000\n</code></pre> <p>Once the UI is running, open http://localhost:5000 in your browser.</p>"},{"location":"integrations/mlflow/#integration-pattern","title":"Integration Pattern","text":"<p>The standard pattern for integrating MLflow into a ROSE <code>SequentialActiveLearner</code> loop involves wrapping the learner's <code>start()</code> iterator:</p> <pre><code>import mlflow\nfrom rose.al import SequentialActiveLearner\n\nasync def main():\n    # 1. Initialize MLflow Run\n    mlflow.set_experiment(\"ROSE_AL_Experiment\")\n\n    with mlflow.start_run():\n        # 2. Log Configuration\n        mlflow.log_params({\n            \"max_iterations\": 10,\n            \"mse_threshold\": 0.01,\n        })\n\n        # 3. Setup ROSE Learner\n        learner = SequentialActiveLearner(asyncflow)\n        # ... register tasks ...\n\n        # 4. Instrument the Control Loop\n        async for state in learner.start(max_iter=10):\n            # Log metrics at each iteration step\n            mlflow.log_metric(\"mse\", state.metric_value, step=state.iteration)\n            mlflow.log_metric(\"labeled_count\", state.labeled_count, step=state.iteration)\n\n            print(f\"Iteration {state.iteration}: MSE {state.metric_value}\")\n\n        # 5. Log Final Artifacts\n        mlflow.sklearn.log_model(final_model, \"surrogate_model\")\n</code></pre>"},{"location":"integrations/mlflow/#what-is-tracked","title":"What is Tracked?","text":""},{"location":"integrations/mlflow/#parameters","title":"Parameters","text":"<p>Parameters are typically logged once at the beginning of the run to record the experimental setup. *   Iteration limits *   Stopping criteria thresholds *   Initial sample sizes *   Batch selection counts</p>"},{"location":"integrations/mlflow/#metrics","title":"Metrics","text":"<p>Metrics are logged at each iteration step using the <code>step</code> parameter in <code>mlflow.log_metric()</code>. This allows you to view learning curves and performance trends over time in the MLflow UI. *   Performance: MSE, Accuracy, R-squared *   Workflow State: Number of labeled samples, remaining pool size *   Adaptive Features: Current uncertainty scores, selection batch sizes</p>"},{"location":"integrations/mlflow/#artifacts-and-model-registry","title":"Artifacts and Model Registry","text":"<p>At the end of the ROSE workflow, you can save: *   The Model: Register the final surrogate model in the MLflow Model Registry for deployment. *   Visualizations: Save plots of error reduction vs. iteration or sample size. *   Data States: Save the final labeled dataset for future reference.</p>"},{"location":"integrations/mlflow/#advanced-mlflowrosetracker-helper","title":"Advanced: MLflowROSETracker Helper","text":"<p>For more complex workflows, the provided example includes an <code>MLflowROSETracker</code> helper class. It encapsulates common tracking logic, making the main workflow code cleaner:</p> <pre><code>tracker = MLflowROSETracker(\"My_Complex_Experiment\")\ntracker.start_experiment(config)\n\nasync for state in learner.start(max_iter=15):\n    # Automatically handles extraction and logging of relevant metrics\n    tracker.log_iteration(state)\n\ntracker.log_model(model, X_sample, y_sample)\ntracker.end_experiment(success=True)\n</code></pre> <p>For the full implementation of this helper, see the mlflow_rose.py source code.</p>"},{"location":"user-guide/acl-metrics/","title":"3.AL Metric","text":""},{"location":"user-guide/acl-metrics/#rose-standard-and-custom-metrics","title":"ROSE Standard and Custom Metrics","text":"<p>ROSE supports different Machine Learning (ML) Metrics such as <code>RMSE</code>, <code>MAE</code>, and <code>F2score</code> and many more.</p>"},{"location":"user-guide/acl-metrics/#standard-metrics","title":"Standard Metrics","text":"<p>For a full list of the supported metrics please refer to the following link ROSE Standard Metrics</p>"},{"location":"user-guide/acl-metrics/#custom-metrics","title":"Custom Metrics","text":"<p>ROSE allows the user to define additional metrics if not supported by default. To define a custom metric, you can do the following:</p> <p>import the operator for the custom metric: </p><pre><code>from rose.metrics import GREATER_THAN_THRESHOLD\n</code></pre><p></p> <p>Now define your <code>@acl.as_stop_criterion</code> with additional args <code>operator</code>: </p><pre><code># Defining the stop criterion with a metric\n@acl.as_stop_criterion(metric_name='custom_metric',\n                       operator=GREATER_THAN_THRESHOLD, threshold=0.8)\nasync def check_metric(*args):\n    return f'python3 check_custom_metric.py'\n</code></pre><p></p> <p>In this way, ROSE will understand the relation between the custom metric and the target threshold value.</p>"},{"location":"user-guide/advanced-acl-workflow/","title":"5.Advanced AL workflow","text":"<p>To support the rapid advancement of AL techniques, ROSE offers an additional approach to building and executing complex AL workflows.</p> <p>In this example, we demonstrate how to express an AL workflow with different levels of parallelism. What does that mean?</p> <p>In some cases, AL workflows may require the execution of N simulation or training tasks concurrently. But not only that\u2014additionally, they may also require the submission of M AL workflows concurrently. This introduces two levels of parallelism: one at the task level and another at the AL workflow level. Such an approach is possible and can be easily expressed and executed using ROSE's custom AL policy.</p> <pre><code>                             (N AL WFs in Parallel)\n          +-------------------+               +-------------------+\n          |      AL WF 1      |               |      AL WF 2      |\n          +-------------------+               +-------------------+\n                   \u2502                                    \u2502\n  +----------------+-----------------+  +----------------+-----------------+\n  |       (N tasks Parallel)         |  |       (N AL tasks Parallel)      |\n  +---------------+  +---------------+  +---------------+  +---------------+\n  | Simulation 1  |  | Simulation 2  |  | Simulation 1  |  | Simulation 2  |\n  +---------------+  +---------------+  +---------------+  +---------------+\n          |                |                    |                 |\n  +---------------+  +---------------+  +---------------+  +---------------+\n  |  Training 1   |  |  Training 2   |  |  Training 1   |  |  Training 2   |\n  +---------------+  +---------------+  +---------------+  +---------------+\n          |                |                    |                 |\n        (...)            (...)                (...)             (...)\n</code></pre> <p>Since we have already learned how to deploy and load ROSE, and how to instruct it to use different resources, we will skip this part and focus only on expressing the AL workflow.</p> <p>First, let's express our tasks:</p> <pre><code>code_path = f'{sys.executable} {os.getcwd()}'\n\n# Define and register the simulation task\n@custom_acl.simulation_task\nasync def simulation(*args):\n    return f'{code_path}/simulation.py'\n\n# Define and register the training task\n@custom_acl.training_task\nasync def training(*args):\n    return f'{code_path}/training.py'\n\n# Define and register the active learning task\n@custom_acl.active_learn_task\nasync def active_learn(*args):\n    return f'{code_path}/active_learn.py'\n\n# Defining the stop criterion with a metric (MSE in this case)\n@custom_acl.as_stop_criterion(metric_name=MODEL_ACCURACY, threshold=0.99)\nasync def check_accuracy(*args):\n    return f'{code_path}/check_accuracy.py'\n\n# Special task that can perform different operation (example post-processing)\n@custom_acl.utility_task()\nasync def post_process_simulation(*args):\n    return f'{code_path}/post_process_simulation.py'\n</code></pre> <p>Now, lets express the core custom AL policy logic. The example below will:</p> <ul> <li>Submits 5 AL workflows in parallel (Workflow parallelism).</li> <li>Each workflow will run for 10 iterations sequentially.</li> <li>Each iteration will submit 3 simulation tasks in parallel (task parallelism).</li> </ul> <pre><code>async def start():\n    # 10 iterations of active learning\n    for acl_iter in range(10):\n        print(f'Starting Iteration-{acl_iter}')\n        simulations = []\n        for i in range(3):\n            # run 3 simulations in parallel\n            simulations.append(simulation())\n\n        post_process_simulation(*simulations)\n\n        # Now run training and active_learn\n        train = training(*simulations)\n        active = await active_learn(simulations, train)\n\n        if check_accuracy(active):\n            print('Accuracy met the threshold')\n            break\n</code></pre> <p>Now, lets submit 5 AL workflows for execution:</p> <pre><code># invoke the custom/user-defined start() method\nresults = await asyncio.gather(*[start() for _ in range(1024)])\n</code></pre>"},{"location":"user-guide/advanced-rl-workflow/","title":"9.Advanced RL workflow","text":"<p>In addition to basic reinforcement learning (RL) workflows, ROSE supports advanced RL workflows that can run multiple environment instances in parallel.</p> <p>The 'ParallelLearner' gives you the ability to run multiple environment tasks simultaneously, each with different parameters, and then merge their experiences for training.</p> <p>This is particularly useful for scenarios where you want to explore different configurations or hyperparameters in parallel, speeding up the learning process. </p><pre><code>                +-------------------+\n                |        RL WF      |\n                +-------------------+\n                            \u2502\n  +-------------------------+---------------------------+\n  |             (N Environment Tasks Parallel)          |\n  +---------------+  +---------------+  +---------------+\n  | Environment 1 |  | Environment 2 |  | Environment 3 |\n  +---------------+  +---------------+  +---------------+\n          |                |                    |\n          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502\n                    +------v------+\n                    |    Merge    |\n                    +------+------+\n                           \u2502\n                    +------v------+\n                    |   Update    |\n                    +------+------+\n                           \u2502\n                    +------v------+\n                    |    Test     |\n                    +-------------+\n</code></pre> Import ROSE parallel RL modules:<p></p> <pre><code>from radical.asyncflow import WorkflowEngine\nfrom rhapsody.backends import RadicalExecutionBackend\nfrom rose.rl.reinforcement_learner import SequentialReinforcementLearner\n</code></pre> <p><code>ParallelExperience</code> is able to run multiple environment instances simultaneously, each with different exploration parameters:</p> <pre><code>async def main():\n\n    execution_engine = await RadicalExecutionBackend(\n        {'runtime': 30,\n        'resource': 'local.localhost'}\n        )\n\n    asyncflow = await WorkflowEngine.create(execution_engine)\n\n    pe = ParallelExperience(asyncflow)\n\n    code_path = f'{sys.executable} {os.getcwd()}'\n\n    # Define multiple environment tasks\n    @pe.environment_task(name='env_1')\n    async def environment_1(*args):\n        return f'{code_path}/environment.py parameter=1'\n\n    @pe.environment_task(name='env_2')\n    async def environment_2(*args):\n        return f'{code_path}/environment.py parameter=2'\n\n    @pe.environment_task(name='env_3')\n    async def environment_3(*args):\n        return f'{code_path}/environment.py parameter=3'\n\n    @pe.environment_task(name='env_4')\n    async def environment_4(*args):\n        return f'{code_path}/environment.py parameter=4'\n\n    @pe.environment_task(name='env_5')\n    async def environment_5(*args):\n        return f'{code_path}/environment.py parameter=5'\n</code></pre> <p>Now that each environment task is defined, we define the rest of the workflow components:</p> <p>Note</p> <p>This snippet of code must be inside an async context or inside <code>main</code> function</p> <pre><code>@pe.update_task\nasync def update(*args):\n    return f'{code_path}/update.py'\n\n@pe.as_stop_criterion(metric_name='MODEL_REWARD', threshold=200, operator=GREATER_THAN_THRESHOLD)\nasync def check_reward(*args):\n    return f'python3 {code_path}/check_reward.py'\n</code></pre> <p>One of the key advantages of ROSE's <code>ParallelExperience</code> learner is that experience banks generated by parallel environments are automatically merged without any manual intervention. This eliminates the complexity of coordinating data aggregation across distributed environment instances.</p> <p>Note that, you do not need to invoke these tasks, as the <code>ParallelExperience</code> will be responsible to manage their invocations.</p> <pre><code># Start the RL training loop and break when stop condition is met\nawait pe.learn()\nawait engine.shutdown()\n</code></pre> <p>This advanced workflow allows you to efficiently explore multiple configurations in parallel, leveraging ROSE's capabilities to manage and merge experiences seamlessly. The <code>ParallelExperience</code> learner is particularly useful for scenarios where you want to speed up the learning process by running multiple environment instances concurrently, each with different parameters or hyperparameter.</p>"},{"location":"user-guide/basic-acl-workflow/","title":"2.Basic AL workflow","text":""},{"location":"user-guide/basic-acl-workflow/#define-your-target-machine-to-run-on","title":"Define your target machine to run on","text":"<p>Import ROSE main modules: </p><pre><code>from rose.metrics import MEAN_SQUARED_ERROR_MSE\nfrom rose.al.active_learner import SequentialActiveLearner\n\nfrom radical.asyncflow import WorkflowEngine\nfrom rhapsody.backends import RadicalExecutionBackend\n</code></pre><p></p> <p>Define your resource engine, as we described in our previous Target Resources step:</p> <pre><code>engine = await RadicalExecutionBackend({'resource': 'local.localhost'})\nasyncflow = await WorkflowEngine.create(engine)\n\nacl = SequentialActiveLearner(asyncflow)\n</code></pre> <p>Now our resource engine is defined, lets define our main AL workflow components:</p> <p>Note</p> <p>The Task object is based on the Radical.Pilot.TaskDescription, meaning that users can pass any <code>args</code> and <code>kwargs</code> that the <code>Radical.Pilot.TaskDescription</code> can accept to the Task object.</p> <pre><code>@acl.simulation_task\nasync def simulation(*args):\n    return 'python3 sim.py'\n\n@acl.training_task\nasync def training(*args):\n    return f'python3 train.py'\n\n@acl.active_learn_task\nasync def active_learn(*args):\n    return f'python3 active.py'\n</code></pre> <p>Tip</p> <p>ROSE supports defining tasks with python code instead of executables (i.e., python scripts, shell scripts, etc.). To do that, the user have to pass the <code>as_executable=False</code> argument to the decorator as follows:</p> <pre><code>@acl.simulation_task(as_executable=False)\nasync def run_simulation(*args) -&gt; dict:\n    \"\"\"Simulate a process and return dummy simulation results.\"\"\"\n    await asyncio.sleep(1)  # Simulate async workload\n    results = {\n        \"input\": args,\n        \"output\": [random.random() for _ in range(5)]\n    }\n    return results\n\n@acl.training_task(as_executable=False)\nasync def run_training(simulation_results: dict) -&gt; dict:\n    \"\"\"Train a dummy model using simulation results.\"\"\"\n    await asyncio.sleep(1)  # Simulate training time\n    model = {\n        \"weights\": [sum(simulation_results[\"output\"]) * 0.1],\n        \"trained_on\": simulation_results[\"input\"]\n    }\n    return model\n\n@acl.active_learn_task(as_executable=False)\nasync def run_active_learning(model: dict) -&gt; dict:\n    \"\"\"Perform a dummy active learning step with the trained model.\"\"\"\n    await asyncio.sleep(1)  # Simulate active learning\n    selected_samples = [random.randint(0, 100) for _ in range(3)]\n    return {\n        \"model_weights\": model[\"weights\"],\n        \"new_samples\": selected_samples\n    }\n</code></pre> <p>Optionally, you can specify a metric to monitor and act as a condition to terminate once your results reach the specified value:</p> <p>Tip</p> <p>Specifying both <code>@acl.as_stop_criterion</code> and <code>max_iter</code> will cause ROSE to follow whichever constraint is satisfied first. Specifying neither will cause an error and eventually a failure to your workflow.</p> <p>Note</p> <p>ROSE  supports custom/user-defined metrics in addition to a wide range of standard metrics. For a list of standard metrics and how to define a custom metrics, please refer to the following link: Standard Metrics.</p> <pre><code># Defining the stop criterion with a metric (MSE in this case)\n@acl.as_stop_criterion(metric_name=MEAN_SQUARED_ERROR_MSE, threshold=0.1)\nasync def check_mse(*args):\n    return f'python3 check_mse.py'\n</code></pre> <p>Warning</p> <p>For any metric function like <code>@acl.as_stop_criterion</code> the invoked script like <code>check_mse.py</code> must return a numerical value.</p> <p>Finally invoke the tasks and register them with the active learner as a workflow.</p> <p>Note</p> <p>In the Sequential Learner, the invocation order of the tasks is predefined order of tasks as follows: <code>simulation</code> --&gt; <code>training</code> --&gt; <code>active_learn</code>.</p> <pre><code># Start the learning loop and break if max_iter = 10 or stop condition is met\nawait acl.start(max_iter=10)\nawait asyncflow.shutdown()\n</code></pre>"},{"location":"user-guide/basic-rl-workflow/","title":"7.Reinforcement Learning","text":""},{"location":"user-guide/basic-rl-workflow/#define-your-target-machine-to-run-on","title":"Define your target machine to run on","text":"<p>Import ROSE main modules: </p><pre><code>from radical.asyncflow import WorkflowEngine\nfrom rhapsody.backends import RadicalExecutionBackend\n\nfrom rose.metrics import GREATER_THAN_THRESHOLD\nfrom rose.rl.reinforcement_learner import SequentialReinforcementLearner\n</code></pre><p></p> <p>Define your resource engine, as we described in our previous Target Resources step: </p><pre><code>engine = await RadicalExecutionBackend({'resource': 'local.localhost'})\nasyncflow = await WorkflowEngine.create(engine)\n\nrl = SequentialReinforcementLearner(asyncflow)\n</code></pre><p></p> <p>Now our resource engine is defined, lets define our main RL workflow components:</p> <pre><code>@rl.environment_task\nasync def environment(*args):\n    return f'python3 environment.py'\n\n@rl.update_task\nasync def update(*args):\n    return f'python3 update.py'\n\n@rl.as_stop_criterion(metric_name='MODEL_REWARD', threshold=200, operator=GREATER_THAN_THRESHOLD)\nasync def check_reward(*args):\n    return 'python3 check_reward.py'\n</code></pre> <p>Warning</p> <p>For any metric function like <code>@rl.as_stop_criterion</code> the invoked script like <code>check_reward.py</code> must return a numerical value.</p> <p>Finally invoke the tasks and register them with the reinforcement learner as a workflow:</p> <pre><code># Start the RL training loop and break when stop condition is met\nawait rl.learn()\n\n# You can also specify maximum iterations\nawait rl.learn(max_iter=10)\nawait asyncflow.shutdown()\n</code></pre>"},{"location":"user-guide/experience/","title":"8.Experience Banks","text":""},{"location":"user-guide/experience/#rose-experience-and-experience-banks","title":"ROSE Experience and Experience Banks","text":"<p>ROSE provides a comprehensive experience management system for Reinforcement Learning workflows through the <code>Experience</code> dataclass and <code>ExperienceBank</code> class.</p>"},{"location":"user-guide/experience/#experience-data-structure","title":"Experience Data Structure","text":"<p>The <code>Experience</code> class captures a single environment interaction containing: - State - Current environment observation - Action - Action taken by the agent - Reward - Reward received from environment - Next State - Resulting environment observation - Done - Boolean indicating episode termination - Info - Optional metadata dictionary</p> <p>Use the helper function to create experiences during environment interactions: </p><pre><code>from rose.rl.experience import Experience, create_experience\n\nexperience = create_experience(state, action, reward, next_state, done, info={\"step\": 42})\n</code></pre><p></p>"},{"location":"user-guide/experience/#experience-bank","title":"Experience Bank","text":"<p>Experience Banks provide persistent storage and efficient sampling for RL experiences:</p> <pre><code>from rose.rl.experience import ExperienceBank\n\n# Create a bank with size limit\nbank = ExperienceBank(max_size=10000)\n\n# Add experiences\nbank.add(experience)\n# Add collection of experiences\nbank.add_batch([experience1, experience2, experience3])\n\n# Sample for training\nbatch = bank.sample(batch_size=32, replace=True)\n</code></pre> <p>ROSE assigns experience banks a unique session ID automatically, or session IDs can be assigned manually. The session ID is used to identify the bank and can be used to save/load the bank to/from disk:</p> <pre><code># Custom session ID\nbank = ExperienceBank(session_id=\"rose_session\")\n\n# Save with auto-generated filename\nfilepath = bank.save() # Output: experience_bank_{date}_{session_id}.pkl\n\n# Save with custom filename\nfilepath = bank.save(work_dir=\"./data\", bank_file=\"experiences.pkl\")\n\n# Load from file\nloaded_bank = ExperienceBank.load(\"./data/experiences.pkl\")\n</code></pre> <p>Experience banks can be merged, allowing for efficient combination of experiences from multiple sources:</p> <pre><code># Create new merged bank\nmerged_bank = bank1.merge(bank2)\n\n# Merge bank2 into bank1 (modifies bank1)\nbank1.merge_inplace(bank2)\n\n# Find all bank files in directory\nbank_files = ExperienceBank.list_saved_banks(\"./data\")\n</code></pre>"},{"location":"user-guide/parallel_learners_docs/","title":"4.Building Parallel Learners","text":""},{"location":"user-guide/parallel_learners_docs/#learners-with-parameterization-tutorial","title":"Learners with Parameterization Tutorial","text":"<p>This tutorial demonstrates how to configure and run multiple learning pipelines concurrently using <code>ParallelActiveLearner</code>. You\u2019ll learn how to:</p> <ul> <li>Set up parallel workflows</li> <li>Configure each learner independently</li> <li>Use per-iteration and adaptive configurations</li> <li>Run learners concurrently with individual stop criteria</li> </ul> <p>Note</p> <p>This approach can be applied for both Active and Reinforcement learners (Sequential and Parallel).</p>"},{"location":"user-guide/parallel_learners_docs/#example-overview","title":"Example Overview","text":"<p>This example includes:</p> <ul> <li>Learner 0: Adaptive config \u2014 increasing labeled data, decreasing noise &amp; learning rate</li> <li>Learner 1: Per-iteration config \u2014 specific checkpoints for tuning</li> <li>Learner 2: Static config \u2014 constant settings throughout</li> <li>All learners run concurrently and independently</li> </ul>"},{"location":"user-guide/parallel_learners_docs/#configuration-modes","title":"Configuration Modes","text":""},{"location":"user-guide/parallel_learners_docs/#adaptive-configuration","title":"\ud83e\udde0 Adaptive Configuration","text":"<ul> <li>Receives iteration number <code>i</code></li> <li>Labeled data: <code>100 + i*50</code></li> <li>Noise: <code>0.1 * (0.95^i)</code></li> <li>Learning rate: <code>0.01 * (0.9^i)</code></li> <li>Batch size increases gradually, capped at 64</li> </ul>"},{"location":"user-guide/parallel_learners_docs/#per-iteration-configuration","title":"\ud83d\udd01 Per-Iteration Configuration","text":"<ul> <li>Iteration keys (e.g., <code>0</code>, <code>5</code>, <code>10</code>) set exact checkpoints</li> <li><code>-1</code> is the fallback/default config</li> <li>Ideal for curriculum learning or scheduled tuning</li> </ul>"},{"location":"user-guide/parallel_learners_docs/#setup","title":"Setup","text":"<p>Warning</p> <p>The entire API of ROSE must be within an <code>async</code> context.</p>"},{"location":"user-guide/parallel_learners_docs/#1-imports-engine","title":"1. Imports &amp; Engine","text":"<pre><code>import os\nimport sys\n\nfrom rose import TaskConfig\nfrom rose import LearnerConfig\n\nfrom rose.al import ParallelActiveLearner\nfrom rose.metrics import MEAN_SQUARED_ERROR_MSE\n\nfrom radical.asyncflow import WorkflowEngine\nfrom rhapsody.backends import RadicalExecutionBackend\n\nengine = await RadicalExecutionBackend(\n    {'runtime': 30,\n     'resource': 'local.localhost'\n     }\n     )\nasyncflow = await WorkflowEngine.create(engine)\nacl = ParallelActiveLearner(asyncflow)\ncode_path = f'{sys.executable} {os.getcwd()}'\n</code></pre>"},{"location":"user-guide/parallel_learners_docs/#1-define-workflow-tasks","title":"1. Define Workflow Tasks","text":"<pre><code>@acl.simulation_task\nasync def simulation(*args, **kwargs):\n    n_labeled = kwargs.get(\"--n_labeled\", 100)\n    n_features = kwargs.get(\"--n_features\", 2)\n\n    return f\"{code_path}/sim.py --n_labeled {n_labeled} --n_features {n_features}\"\n\n@acl.training_task\nasync def training(*args, **kwargs):\n    learning_rate = kwargs.get(\"--learning_rate\", 0.1)\n    return f'{code_path}/train.py --learning_rate {learning_rate}'\n\n@acl.active_learn_task\nasync def active_learn(*args, **kwargs):\n    return f'{code_path}/active.py'\n\n@acl.as_stop_criterion(metric_name=MEAN_SQUARED_ERROR_MSE, threshold=0.1)\nasync def check_mse(*args, **kwargs):\n    return f'{code_path}/check_mse.py'\n</code></pre>"},{"location":"user-guide/parallel_learners_docs/#configuration-approaches","title":"Configuration Approaches","text":""},{"location":"user-guide/parallel_learners_docs/#approach-1-static-configuration","title":"Approach 1: Static Configuration","text":"<pre><code>results = await acl.start(\n    parallel_learners=2,\n    max_iter=10,\n    learner_configs=[\n        LearnerConfig(\n            simulation=TaskConfig(kwargs={\"--n_labeled\": \"200\", \"--n_features\": 2}),\n            training=TaskConfig(kwargs={\"--learning_rate\": \"0.01\"})\n        ),\n        LearnerConfig(\n            simulation=TaskConfig(kwargs={\"--n_labeled\": \"300\", \"--n_features\": 4}),\n            training=TaskConfig(kwargs={\"--learning_rate\": \"0.005\"})\n        )\n    ]\n)\n</code></pre>"},{"location":"user-guide/parallel_learners_docs/#approach-2-per-iteration-configuration","title":"Approach 2: Per-Iteration Configuration","text":"<pre><code>results = await acl.start(\n    parallel_learners=3,\n    max_iter=15,\n    learner_configs=[\n        LearnerConfig(\n            simulation=TaskConfig(kwargs={\"--n_labeled\": \"200\", \"--n_features\": 2})\n        ),\n        LearnerConfig(\n            simulation={\n                0: TaskConfig(kwargs={\"--n_labeled\": \"100\"}),\n                5: TaskConfig(kwargs={\"--n_labeled\": \"200\"}),\n                10: TaskConfig(kwargs={\"--n_labeled\": \"400\"}),\n                -1: TaskConfig(kwargs={\"--n_labeled\": \"500\"})\n            },\n            training={\n                0: TaskConfig(kwargs={\"--learning_rate\": \"0.01\"}),\n                5: TaskConfig(kwargs={\"--learning_rate\": \"0.005\"}),\n                -1: TaskConfig(kwargs={\"--learning_rate\": \"0.001\"})\n            }\n        ),\n        None  # Default to base task behavior\n    ]\n)\n</code></pre> <p>Per-Iteration Config Keys</p> <p>Use numeric keys for specific iterations and -1 as a fallback.</p>"},{"location":"user-guide/parallel_learners_docs/#approach-3-adaptive-configuration","title":"Approach 3: Adaptive Configuration","text":"<pre><code>adaptive_sim = acl.create_adaptive_schedule('simulation',\n    lambda i: {\n        'kwargs': {\n            '--n_labeled': str(100 + i * 50),\n            '--n_features': 2,\n            '--noise_level': str(0.1 * (0.95 ** i))\n        }\n    })\n\nadaptive_train = acl.create_adaptive_schedule('training',\n    lambda i: {\n        'kwargs': {\n            '--learning_rate': str(0.01 * (0.9 ** i)),\n            '--batch_size': str(min(64, 32 + i * 4))\n        }\n    })\n\nresults = await acl.start(\n    parallel_learners=2,\n    max_iter=20,\n    learner_configs=[\n        LearnerConfig(simulation=adaptive_sim, training=adaptive_train),\n        LearnerConfig(\n            simulation=TaskConfig(kwargs={\"--n_labeled\": \"300\", \"--n_features\": 4}),\n            training=TaskConfig(kwargs={\"--learning_rate\": \"0.005\"})\n        )\n    ]\n)\n</code></pre>"},{"location":"user-guide/parallel_learners_docs/#full-example-all-approaches-combined","title":"Full Example: All Approaches Combined","text":"<pre><code>adaptive_sim = acl.create_adaptive_schedule('simulation',\n    lambda i: {\n        'kwargs': {\n            '--n_labeled': str(100 + i * 50),\n            '--n_features': 2\n        }\n    })\n\nresults = await acl.start(\n    parallel_learners=3,\n    max_iter=15,\n    learner_configs=[\n        LearnerConfig(simulation=adaptive_sim),  # Adaptive\n        LearnerConfig(                           # Per-iteration\n            simulation={\n                0: TaskConfig(kwargs={\"--n_labeled\": \"150\", \"--n_features\": 3}),\n                7: TaskConfig(kwargs={\"--n_labeled\": \"250\", \"--n_features\": 3}),\n                -1: TaskConfig(kwargs={\"--n_labeled\": \"400\", \"--n_features\": 3})\n            }\n        ),\n        LearnerConfig(                           # Static\n            simulation=TaskConfig(kwargs={\"--n_labeled\": \"300\", \"--n_features\": 4})\n        )\n    ]\n)\n\nawait acl.shutdown()\n</code></pre>"},{"location":"user-guide/parallel_learners_docs/#execution-details","title":"Execution Details","text":"<p>Concurrent Execution</p> <p>All learners run in parallel and independently. The workflow completes when all learners either reach max_iter or meet their stop criterion.</p> <p>Stop Criteria</p> <p>Each learner evaluates its own stop condition. One learner stopping does not affect others.</p> <p>Performance Tip</p> <p>Match the number of parallel learners to available resources. Overloading can slow down execution.</p>"},{"location":"user-guide/parallel_learners_docs/#quick-reference","title":"Quick Reference","text":"<p><code>create_iteration_schedule(task_name, schedule)</code></p> <pre><code>schedule = {\n    0: {'kwargs': {'--learning_rate': '0.01'}},\n    5: {'kwargs': {'--learning_rate': '0.005'}},\n    -1: {'kwargs': {'--learning_rate': '0.001'}}\n}\nconfig = acl.create_iteration_schedule('training', schedule)\n</code></pre> <p><code>create_adaptive_schedule(task_name, fn)</code></p> <pre><code>def lr_decay(i):\n    return {'kwargs': {'--learning_rate': str(0.01 * (0.95 ** i))}}\n\nadaptive_config = acl.create_adaptive_schedule('training', lr_decay)\n</code></pre>"},{"location":"user-guide/parallel_learners_docs/#next-steps","title":"Next Steps","text":"<ul> <li> <p>\ud83e\uddea Try different active learning algorithms per learner</p> </li> <li> <p>\ud83c\udfaf Use per-iteration configs to design curriculum learning</p> </li> <li> <p>\ud83d\udcca Run parameter sweeps</p> </li> <li> <p>\ud83d\ude80 Scale learners to match compute resources</p> </li> </ul>"},{"location":"user-guide/target-resources/","title":"1.Target Resources","text":""},{"location":"user-guide/target-resources/#target-machines-for-executing-al-workflows","title":"Target Machines for Executing AL Workflows","text":"<p>ROSE enables the orchestration of ML Surrogate building workflows on diverse computing resources using radical.asyncflow. Below, we will show how you can specify your <code>local computer</code> and <code>remote HPC machine</code> as target resources using the <code>RadicalExecutionBackend</code> from RHAPSODY.</p>"},{"location":"user-guide/target-resources/#local-computer","title":"Local Computer","text":"<p>For local execution, user can use their desktops, laptops, and their own small clusters to execute their AL workflows as follows: </p><pre><code>import os\n\nfrom radical.asyncflow import WorkflowEngine\nfrom rhapsody.backends import RadicalExecutionBackend\n\nfrom rose.al.active_learner import SequentialActiveLearner\n\nengine = await RadicalExecutionBackend(\n    {'runtime': 30,\n    'resource': 'local.localhost'})\n\nasyncflow = await WorkflowEngine.create(engine)\n\nacl = SequentialActiveLearner(asyncflow)\n</code></pre><p></p>"},{"location":"user-guide/target-resources/#hpc-resources","title":"HPC Resources","text":"<p>To execute AL workflows on HPC machines, users must have an active allocation on the target machine and specify their resource requirements, as well as the time needed to execute their workflows. Remember, ROSE uses <code>RadicalExecutionBackend</code> from RHAPSODY (<code>rhapsody-py</code>) which is an interface for RADICAL-Pilot runtime system. For more information on how to access, set up, and execute workflows on HPC machines, refer to the following link RADICAL-Pilot Job Submission:</p> <pre><code>import os\n\nfrom radical.asyncflow import WorkflowEngine\nfrom rhapsody.backends import RadicalExecutionBackend\n\nfrom rose.al.active_learner import SequentialActiveLearner\n\n\nhpc_engine = await RadicalExecutionBackend(\n    {'runtime': 30, 'cores': 4096,\n     'gpus' : 4, 'resource': 'tacc.frontera'})\n\nasyncflow = await WorkflowEngine.create(hpc_engine)\n\nacl = SequentialActiveLearner(asyncflow)\n</code></pre>"},{"location":"user-guide/uq_based-acl-workflow/","title":"Uq based acl workflow","text":"<p>To accelerate the development of UQ-driven active learning methods, ROSE provides a flexible approach for composing and executing complex AL workflows.</p> <p>In this example, we illustrate how to define a UQ\u2013AL workflow that supports multiple levels of parallelism.</p> <p>In many cases, an AL cycle requires evaluating multiple candidate models or simulations concurrently to quantify predictive uncertainty and guide sample selection. Beyond that, it may also require running several independent AL workflows in parallel to\u00a0exploring multiple uncertainty metrics.</p> <p>This introduces two levels of parallelism:</p> <ul> <li>Task-level parallelism for concurrent model training, inference, or simulation.</li> <li>Workflow-level parallelism for executing multiple UQ\u2013AL loops side by side.</li> </ul> <p>Both levels can be naturally expressed and efficiently executed using ROSE\u2019s custom AL policy, enabling scalable and adaptive uncertainty-aware learning. </p><pre><code>                             (N AL WFs in Parallel)\n          +-------------------+               +-------------------+\n          |      UQ WF 1      |               |      UQ WF 2      |\n          +-------------------+               +-------------------+\n                   \u2502                                    \u2502\n  +----------------+-----------------+  +----------------+-----------------+\n  |       (N tasks Parallel)         |  |       (N AL tasks Parallel)      |\n  +---------------+  +---------------+  +---------------+  +---------------+\n  | Simulation 1,2,..............n   |  | Simulation 1,2,..............n   |\n  +---------------+  +---------------+  +---------------+  +---------------+\n          |                |                    |                 |\n  +---------------+  +---------------+  +---------------+  +---------------+\n  |  Train Model  1,2,...........m   |  |  Train Model  1,2,...........m   |\n  +---------------+  +---------------+  +---------------+  +---------------+\n          |                |                    |                 |\n    +-----------------------------+        +-----------------------------+\n    |      AL based on UQ WF 1    |        |    AL based on UQ WF 1      |\n    +-----------------------------+        +-----------------------------+\n</code></pre><p></p>"},{"location":"user-guide/uq_based-acl-workflow/#uq-driven-active-learning-with-parallel-workflows","title":"UQ-Driven Active Learning with Parallel Workflows","text":"<p>The UQ Active Learning (UQ-AL) workflow extends the traditional active learning loop by running multiple models in parallel. Instead of relying on a single model to guide the selection of new samples, the workflow trains and evaluates an ensemble of models simultaneously. Predictions from all models are then aggregated to compute uncertainty metrics, which are used to identify the most uncertain examples to the next AL iteration.</p>"},{"location":"user-guide/uq_based-acl-workflow/#key-component-paralleluqlearner","title":"Key Component: <code>ParallelUQLearner</code>","text":"<ul> <li>Trains multiple models in parallel.</li> <li>Collects predictions from all models on candidate data points.</li> <li>Computes UQ metrics (e.g., entropy, variance, disagreement) across the ensemble.</li> <li>Selects the most uncertain samples for labeling or simulation.</li> </ul>"},{"location":"user-guide/uq_based-acl-workflow/#new-task-types","title":"New Task Types","text":"<p>To support this approach, two new task types have been introduced:</p> <ol> <li> <p><code>prediction_task</code></p> </li> <li> <p>Runs inference for each model in the ensemble.</p> </li> <li>Produces prediction outputs that will be used in the UQ calculation.</li> </ol> <pre><code>code_path = f'{sys.executable} {os.getcwd()}'\n\n# Define and register the prediction task\n@learner.prediction_task()\nasync def prediction(*args):\n    return f'{code_path}/predict.py'\n</code></pre> <ol> <li> <p><code>uncertainty_quantification</code></p> </li> <li> <p>Aggregates predictions from all models.</p> </li> <li>Computes uncertainty metrics.</li> <li>Returns the top-k uncertain samples for the next active learning cycle.</li> </ol> <pre><code># Defining the uncertainty quantification with a metric (PREDICTIVE_ENTROPY in this case)\n@learner.uncertainty_quantification(uq_metric_name=PREDICTIVE_ENTROPY,\n                                    threshold=1.0,\n                                    query_size=10)\nasync def check_uq(*args):\n    return f'{code_path}/check_uq.py'xs\n</code></pre>"},{"location":"user-guide/uq_based-acl-workflow/#workflow-summary","title":"Workflow Summary","text":"<ol> <li>Launch multiple prediction tasks in parallel.</li> <li>Collect outputs and pass them to the uncertainty quantification task.</li> <li>Identify the most uncertain samples.</li> <li>Add these samples to the training set for the next AL iteration.</li> </ol> <p>This design allows parallel training and uncertainty-aware sampling within AL workflows, making it easy to scale across many models or candidate datasets.</p>"},{"location":"user-guide/uq_based-acl-workflow/#getting-started-with-paralleluqlearner-in-rose","title":"Getting Started with ParallelUQLearner in ROSE","text":"<p>Import and Initialize the UQ Learner</p> <pre><code>from rose.uq.uq_active_learner import ParallelUQLearner\nlearner = ParallelUQLearner(asyncflow)\n</code></pre> <p>Run the learning (Active Learning Loop)</p> <pre><code>PIPELINES = ['UQ_learner1', 'UQ_learner2']\n\nresults = await learner.start(\n    learner_names=PIPELINES,\n    model_names=MODELS,\n    learner_configs=learner_configs,\n    max_iter=ITERATIONS,\n    num_predictions=NUM_PREDICTION\n)\n</code></pre> <p>Save Results to File and Shutdown the Learner</p> <pre><code>print('Progress is done with Final Results:')\nprint(results)\n\nwith open(Path(os.getcwd(), 'UQ_training_results.json'), 'w') as f:\n    json.dump(results, f, indent=4)\n\nawait learner.shutdown()\n</code></pre>"},{"location":"user-guide/uq_based-acl-workflow/#defining-costom-uq-metric","title":"Defining costom UQ metric","text":"<pre><code>from rose.uq import UQScorer, register_uq, UQ_REGISTRY\n\n@register_uq(\"custom_uq\")\ndef confidence_score(self, mc_preds):\n    \"\"\"\n    Custom classification metric: 1 - max predicted probability.\n    Lower max prob = higher uncertainty.\n    \"\"\"\n    mc_preds, _ = self._validate_inputs(mc_preds)\n    mean_probs = np.mean(mc_preds, axis=0)      # [n_instances, n_classes]\n    max_prob = np.max(mean_probs, axis=1)\n    return 1.0 - max_prob\n\n\nscorer = UQScorer(task_type=\"classification\")\nprint(\"Available metrics:\", list(UQ_REGISTRY.keys()))\n\nUQ_METRIC_NAME='custom_uq'\n</code></pre>"},{"location":"user-guide/visualization/","title":"6.Visualization","text":""}]}