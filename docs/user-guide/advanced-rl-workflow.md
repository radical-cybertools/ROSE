In addition to basic reinforcement learning (RL) workflows, ROSE supports advanced RL workflows that can run multiple environment instances in parallel. 

The 'ParallelLearner' gives you the ability to run multiple environment tasks simultaneously, each with different parameters, and then merge their experiences for training. 

This is particularly useful for scenarios where you want to explore different configurations or hyperparameters in parallel, speeding up the learning process.
```sh            

                +-------------------+
                |        RL WF      |
                +-------------------+
                            │
  +-------------------------+---------------------------+  
  |             (N Environment Tasks Parallel)          | 
  +---------------+  +---------------+  +---------------+  
  | Environment 1 |  | Environment 2 |  | Environment 3 |  
  +---------------+  +---------------+  +---------------+  
          |                |                    |
          └────────────────┼────────────────────┘
                           │
                    +------v------+ 
                    |    Merge    | 
                    +------+------+ 
                           │        
                    +------v------+ 
                    |   Update    | 
                    +------+------+ 
                           │        
                    +------v------+ 
                    |    Test     | 
                    +-------------+ 
```
Import ROSE parallel RL modules:

```python
from rose.rl.learner import ParallelExperience
from rose.engine import Task, ResourceEngine
```

Define your resource engine and parallel experience learner:
```python
engine = ResourceEngine({'runtime': 60,
                         'resource': 'local.localhost'})
pe = ParallelExperience(engine)
```

`ParallelExperience` is able to run multiple environment instances simultaneously, each with different exploration parameters:

```python
code_path = f'{sys.executable} {os.getcwd()}'

# Define multiple environment tasks
@pe.environment_task(name='env_1')
def environment_1(*args):
    return Task(executable=f'{code_path}/environment.py parameter=1')

@pe.environment_task(name='env_2')
def environment_2(*args):
    return Task(executable=f'{code_path}/environment.py parameter=2')

@pe.environment_task(name='env_3')
def environment_3(*args):
    return Task(executable=f'{code_path}/environment.py parameter=3')

@pe.environment_task(name='env_4')
def environment_4(*args):
    return Task(executable=f'{code_path}/environment.py parameter=4')

@pe.environment_task(name='env_5')
def environment_5(*args):
    return Task(executable=f'{code_path}/environment.py parameter=5')
```

Now that each environment task is defined, we define the rest of the workflow components:

```python
@pe.update_task
def update(*args):
    return Task(executable=f'{code_path}/update.py', arguments=args)

@pe.as_stop_criterion(metric_name='MODEL_REWARD', threshold=200, operator=GREATER_THAN_THRESHOLD)
def check_reward(*args):
    return Task(executable='python3 check_reward.py')
```

One of the key advantages of ROSE's `ParallelExperience` learner is that experience banks generated by parallel environments are automatically merged without any manual intervention. This eliminates the complexity of coordinating data aggregation across distributed environment instances.

Finally, invoke the tasks and register them with the parallel experience learner as a workflow:

```python
env_1 = environment_1()
env_2 = environment_2()
env_3 = environment_3()
env_4 = environment_4()
env_5 = environment_5()
upd = update()
stop_cond = check_reward()

# Start the RL training loop and break when stop condition is met
pe.learn()
engine.shutdown()
```

This advanced workflow allows you to efficiently explore multiple configurations in parallel, leveraging ROSE's capabilities to manage and merge experiences seamlessly. The `ParallelExperience` learner is particularly useful for scenarios where you want to speed up the learning process by running multiple environment instances concurrently, each with different parameters or hyperparameters.