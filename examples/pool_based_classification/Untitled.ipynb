{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eacf98-135a-429b-9e69-9b078718b6ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from rose.metrics import MODEL_ACCURACY\n",
    "from rose.engine import Task, ResourceEngine\n",
    "from rose.learner import SequentialActiveLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f330e9a6-4973-40a2-8c89-0d757239054c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "engine = ResourceEngine({'cores': 64,\n",
    "                         'runtime': 60,\n",
    "                         'resource': 'ncsa.delta', \n",
    "                         'access_schema': 'interactive'})\n",
    "\n",
    "learner = SequentialActiveLearner(engine)\n",
    "code_path = f'{sys.executable} /u/alsaadi1/RADICAL/ROSE/examples/pool_based_classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfdeaa9-9b47-4c54-a45d-d014f042774b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define and register the simulation task\n",
    "@learner.simulation_task\n",
    "def simulation(*args):\n",
    "    return Task(cores_per_rank=4,\n",
    "                executable=f'{code_path}/simulation.py')\n",
    "\n",
    "# Define and register the training task\n",
    "@learner.training_task\n",
    "def training(*args):\n",
    "    return Task(cores_per_rank=12,\n",
    "                executable=f'{code_path}/training.py')\n",
    "\n",
    "# Define and register the active learning task\n",
    "@learner.active_learn_task\n",
    "def active_learn(*args):\n",
    "    return Task(cores_per_rank=12,\n",
    "                executable=f'{code_path}/active_learn.py')\n",
    "\n",
    "@learner.as_stop_criterion(metric_name=MODEL_ACCURACY, threshold=90)\n",
    "def check_acc(*args):\n",
    "    return Task(cores_per_rank=12,\n",
    "                executable=f'{code_path}/check_metric.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bed5c0-df08-4abc-b9bb-11f4d773fec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now, call the tasks and teach\n",
    "simul = simulation()\n",
    "train = training()\n",
    "active = active_learn()\n",
    "check = check_acc()\n",
    "\n",
    "# Start the teaching process\n",
    "learner.teach(max_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e382a8-31a5-4c88-91df-35244c4d0e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ve.jupyter]",
   "language": "python",
   "name": "conda-env-ve.jupyter-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
