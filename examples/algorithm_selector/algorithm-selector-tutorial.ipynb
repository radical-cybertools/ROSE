{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4ac3f58-1070-488f-83d8-23ce0441c18d",
   "metadata": {},
   "source": [
    "# This notebook will show how to use the ROSE framework to run two active learning algorithms in **asynchronously** (in parallel) and select the best one based on a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c653f197-c2da-4222-86b9-716b75ae03b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "\n",
    "from rose.learner import AlgorithmSelector\n",
    "from rose.metrics import MEAN_SQUARED_ERROR_MSE\n",
    "\n",
    "from radical.flow import WorkflowEngine, ResourceEngine, Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735f0f1e-7a5a-4fec-acbb-b46507c48576",
   "metadata": {},
   "source": [
    "Let us prepare our execution engine using a local resource (user computer). We will ask for 30 minutes as this example will run fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939fd0ac-fdfd-4c9c-94c8-bea12198aab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = ResourceEngine({'runtime': 30,\n",
    "                         'resource': 'local.localhost'})\n",
    "\n",
    "algo_selector = AlgorithmSelector(engine)\n",
    "code_path = f'{sys.executable} {os.getcwd()}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd7dd99-e05e-48b3-93c5-3828fd39e717",
   "metadata": {},
   "source": [
    "We will define our active learning workflow components like our previous tutorials. Please note that, unlike the previous tutorials, we defined **two** active learning tasks (`algo1` and `algo2`). ROSE will select the best based on the number of iterations and the final selected metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e838a38-7822-432f-b962-d5a4ed3169d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and register the simulation task\n",
    "@algo_selector.simulation_task\n",
    "async def simulation(*args):\n",
    "    return Task(executable=f'{code_path}/sim.py')\n",
    "\n",
    "# Define and register the training task\n",
    "@algo_selector.training_task\n",
    "async def training(*args):\n",
    "    return Task(executable=f'{code_path}/train.py')\n",
    "\n",
    "# Define and register Multiple AL tasks\n",
    "@algo_selector.active_learn_task(name='algo_1')\n",
    "async def active_learn_1(*args):\n",
    "    return Task(executable=f'{code_path}/active_1.py')\n",
    "\n",
    "@algo_selector.active_learn_task(name='algo_2')\n",
    "async def active_learn_2(*args):\n",
    "    return Task(executable=f'{code_path}/active_2.py')\n",
    "\n",
    "# Defining the stop criterion with a metric (MSE in this case)\n",
    "@algo_selector.as_stop_criterion(metric_name=MEAN_SQUARED_ERROR_MSE, threshold=0.01)\n",
    "async def check_mse(*args):\n",
    "    return Task(executable=f'{code_path}/check_mse.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f27f553-0a80-4c1b-9826-acc40396320a",
   "metadata": {},
   "source": [
    "Let us invoke our workflow and instruct ROSE to select one of both algorithms. Note that since we are running from within a Jupyter Notebook, then we only need to do `await run_and_shutdown()` and not `asyncio.run(run_and_shutdown())` as we are already inside a `running loop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f05322-e11e-4df9-90ec-89f45f956015",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_and_shutdown():\n",
    "    # Now, call the tasks and teach\n",
    "    simul = simulation()\n",
    "    train = training()\n",
    "    active_1 = active_learn_1()\n",
    "    active_2 = active_learn_2()\n",
    "    stop_cond = check_mse()\n",
    "    \n",
    "    # Start the teaching process\n",
    "    await algo_selector.teach_and_select(max_iter=4)\n",
    "    engine.shutdown()\n",
    "\n",
    "await run_and_shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca42e74-53dc-4b75-8b66-d366bbe6d786",
   "metadata": {},
   "source": [
    "Once the execution is done, we can plot the results and of each algorithm as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8ec69e-3364-4d11-b59f-41787cfa4042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "results = algo_selector.algorithm_results\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(results).T  # Transpose to have algorithms as index\n",
    "\n",
    "# Create a figure with two subplots: one for iterations and one for last_result\n",
    "fig, ax = plt.subplots(1, 2, figsize=(7, 2))\n",
    "\n",
    "# Plot iterations\n",
    "df['iterations'].plot(kind='bar', ax=ax[0], color='skyblue', title='Number of Iterations Per Algorithm', edgecolor='black')\n",
    "ax[0].set_ylabel('No. Iterations')\n",
    "\n",
    "# Plot last_result\n",
    "df['last_result'].plot(kind='bar', ax=ax[1], color='orange', title='Metric Value Per Algorithm', edgecolor='black')\n",
    "ax[1].set_ylabel('MSE Value')\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8165f6c-df8d-49d1-93e9-a1066e8e465a",
   "metadata": {},
   "source": [
    "### What do the above plots tell us?\n",
    "\n",
    "The **Algorithm Selector** evaluates two different active learning algorithms, `algo_1` and `algo_2`, using the same input data. The left plot shows the number of iterations each algorithm required to reach convergence, while the right plot compares their Mean Squared Error (MSE) performance.\n",
    "\n",
    "From the results, we can observe that algo_2 required more iterations to converge compared to algo_1, indicating a potentially longer training time. However, when analyzing the MSE values, algo_2 achieved a lower error, suggesting better predictive performance. This trade-off between convergence speed and accuracy is an important consideration when selecting an active learning strategy. In practical applications, users may prioritize either efficiency (fewer iterations) or model accuracy (lower MSE) depending on their specific requirements.\n",
    "\n",
    "More importantly is that all of the work above was done in an **embarrassingly parallel** approach, and **effortlessly**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
