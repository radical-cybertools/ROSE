{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ed7606e-f61f-4230-9fd6-56be5c302d9e",
   "metadata": {},
   "source": [
    "# What is this tutorial\n",
    "This notebook demonstrates how to run a reinforcement learning workflow using ROSE's reinforcement learner. \n",
    "It will show how to:\n",
    "* Define and register the environment and update tasks\n",
    "* Use a stop criterion to terminate training when a target reward is met\n",
    "* Run a sequential reinforcement learning loop with policy gradient methods\n",
    "\n",
    "## Sequential Reinforcement Learner\n",
    "\n",
    "In this example, we will learn how to use ROSE API to build and submit a `single` Reinforcement Learner that either stops when the performance metric threshold is `met` or the number of iterations the user specified is reached (in this case, 100 iterations). This example uses the REINFORCE policy gradient algorithm for the CartPole environment.\n",
    "\n",
    "\n",
    "                                                  ┌────────────────────────┐\n",
    "                                                  │      ENVIRONMENT       │\n",
    "                                                  │ (Run the policy and    │\n",
    "                                                  │   gather experience)   │\n",
    "                                                  └────────────┬───────────┘\n",
    "                                                               │\n",
    "                                                               ▼\n",
    "                                                  ┌────────────────────────┐\n",
    "                                                  │     POLICY UPDATE      │\n",
    "                                                  │ (Update the policy     │\n",
    "                                                  │  using experiences)    │\n",
    "                                                  └────────────┬───────────┘\n",
    "                                                               │\n",
    "                                                               ▼\n",
    "                                                  ┌────────────────────────┐\n",
    "                                                  │      POLICY TEST       │\n",
    "                                                  │ (Test the performance  │\n",
    "                                                  │   of the new policy)   │\n",
    "                                                  └────────────┬───────────┘\n",
    "                                                               │\n",
    "                                                               ▼\n",
    "                                                  ┌────────────────────────┐\n",
    "                                                  │  IMPROVED POLICY LOOP  │\n",
    "                                                  │(Repeat for N iters     │\n",
    "                                                  │   or performance goal) │\n",
    "                                                  └────────────────────────┘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1c26fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import asyncio\n",
    "import logging\n",
    "\n",
    "from typing import Dict, List, Tuple, Any\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Task imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gymnasium as gym\n",
    "\n",
    "# ROSE top layer imports\n",
    "from rose.metrics import GREATER_THAN_THRESHOLD\n",
    "from rose.rl.reinforcement_learner import SequentialReinforcementLearner\n",
    "\n",
    "# ROSE Bottom layers imports\n",
    "from radical.asyncflow import WorkflowEngine\n",
    "from radical.asyncflow import ConcurrentExecutionBackend\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from radical.asyncflow.logging import init_default_logger\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26380e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    env_id: str = \"CartPole-v1\"\n",
    "    seed: int = 42\n",
    "    hidden_size: int = 128\n",
    "    gamma: float = 0.99\n",
    "    lr: float = 3e-3\n",
    "    episodes: int = 1000\n",
    "    batch_size: int = 10\n",
    "    reward_solve_threshold: float = 475.0\n",
    "    device: str = \"cpu\"\n",
    "    model_path: str = \"cartpole_policy.pt\"\n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eb5f4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, obs_dim: int, hidden: int, n_actions: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(obs_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, n_actions),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def action_dist(self, obs: np.ndarray) -> torch.distributions.Categorical:\n",
    "        obs_t = torch.as_tensor(obs, dtype=torch.float32)\n",
    "        logits = self.forward(obs_t)\n",
    "        return torch.distributions.Categorical(logits=logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9442f635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m2025-10-29 14:57:53.794\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[root]\u001b[0m │ Logger configured successfully - Console: INFO, File: disabled (N/A), Structured: disabled, Style: modern\n",
      "\u001b[90m2025-10-29 14:57:53.795\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[main]\u001b[0m │ Starting Reinforcement Learning with ROSE...\n",
      "Starting Sequential RL Learner\n",
      "Starting Iteration-0\n",
      "\u001b[90m2025-10-29 14:57:53.796\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:57:53.832\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000001 is in DONE state\n",
      "\u001b[90m2025-10-29 14:57:53.843\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:57:54.490\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000002 is in DONE state\n",
      "\u001b[90m2025-10-29 14:57:54.501\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:57:54.521\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000003 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (35.6).\n",
      "\u001b[90m2025-10-29 14:57:54.522\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:57:54.562\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000004 is in DONE state\n",
      "\u001b[90m2025-10-29 14:57:54.573\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:57:54.584\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000005 is in DONE state\n",
      "Starting Iteration-1\n",
      "\u001b[90m2025-10-29 14:57:54.586\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:57:54.618\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000006 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (67.8).\n",
      "\u001b[90m2025-10-29 14:57:54.618\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:57:54.657\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000007 is in DONE state\n",
      "\u001b[90m2025-10-29 14:57:54.668\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:57:54.676\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000008 is in DONE state\n",
      "Starting Iteration-2\n",
      "\u001b[90m2025-10-29 14:57:54.679\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:57:54.710\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000009 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (61.4).\n",
      "\u001b[90m2025-10-29 14:57:54.711\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:57:54.866\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000010 is in DONE state\n",
      "\u001b[90m2025-10-29 14:57:54.876\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:57:54.890\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000011 is in DONE state\n",
      "Starting Iteration-3\n",
      "\u001b[90m2025-10-29 14:57:54.890\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:57:54.931\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000012 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (57.2).\n",
      "\u001b[90m2025-10-29 14:57:54.932\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:57:54.981\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000013 is in DONE state\n",
      "\u001b[90m2025-10-29 14:57:54.991\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:57:54.998\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000014 is in DONE state\n",
      "Starting Iteration-4\n",
      "\u001b[90m2025-10-29 14:57:55.003\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:57:55.073\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000015 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (119.8).\n",
      "\u001b[90m2025-10-29 14:57:55.074\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:57:55.168\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000016 is in DONE state\n",
      "\u001b[90m2025-10-29 14:57:55.179\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:57:55.188\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000017 is in DONE state\n",
      "Starting Iteration-5\n",
      "\u001b[90m2025-10-29 14:57:55.189\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:57:55.217\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000018 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (46.2).\n",
      "\u001b[90m2025-10-29 14:57:55.218\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:57:55.267\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000019 is in DONE state\n",
      "\u001b[90m2025-10-29 14:57:55.278\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:57:55.283\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000020 is in DONE state\n",
      "Starting Iteration-6\n",
      "\u001b[90m2025-10-29 14:57:55.290\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:57:55.330\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000021 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (75.0).\n",
      "\u001b[90m2025-10-29 14:57:55.331\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:57:55.393\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000022 is in DONE state\n",
      "\u001b[90m2025-10-29 14:57:55.404\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:57:55.410\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000023 is in DONE state\n",
      "Starting Iteration-7\n",
      "\u001b[90m2025-10-29 14:57:55.415\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:57:55.454\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000024 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (64.6).\n",
      "\u001b[90m2025-10-29 14:57:55.455\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:57:55.525\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000025 is in DONE state\n",
      "\u001b[90m2025-10-29 14:57:55.536\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:57:55.545\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000026 is in DONE state\n",
      "Starting Iteration-8\n",
      "\u001b[90m2025-10-29 14:57:55.546\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:57:55.591\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000027 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (64.0).\n",
      "\u001b[90m2025-10-29 14:57:55.592\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:57:55.669\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000028 is in DONE state\n",
      "\u001b[90m2025-10-29 14:57:55.679\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:57:55.685\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000029 is in DONE state\n",
      "Starting Iteration-9\n",
      "\u001b[90m2025-10-29 14:57:55.691\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:57:55.724\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000030 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (72.0).\n",
      "\u001b[90m2025-10-29 14:57:55.725\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:57:55.828\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000031 is in DONE state\n",
      "\u001b[90m2025-10-29 14:57:55.839\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:57:55.846\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000032 is in DONE state\n",
      "Starting Iteration-10\n",
      "\u001b[90m2025-10-29 14:57:55.851\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:57:55.881\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000033 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (69.6).\n",
      "\u001b[90m2025-10-29 14:57:55.882\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:57:55.965\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000034 is in DONE state\n",
      "\u001b[90m2025-10-29 14:57:55.976\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:57:55.981\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000035 is in DONE state\n",
      "Starting Iteration-11\n",
      "\u001b[90m2025-10-29 14:57:55.987\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:57:56.022\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000036 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (97.0).\n",
      "\u001b[90m2025-10-29 14:57:56.023\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:57:56.146\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000037 is in DONE state\n",
      "\u001b[90m2025-10-29 14:57:56.156\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:57:56.166\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000038 is in DONE state\n",
      "Starting Iteration-12\n",
      "\u001b[90m2025-10-29 14:57:56.167\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:57:56.198\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000039 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (80.2).\n",
      "\u001b[90m2025-10-29 14:57:56.198\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:57:56.269\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000040 is in DONE state\n",
      "\u001b[90m2025-10-29 14:57:56.279\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:57:56.285\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000041 is in DONE state\n",
      "Starting Iteration-13\n",
      "\u001b[90m2025-10-29 14:57:56.291\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:57:56.331\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000042 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (109.2).\n",
      "\u001b[90m2025-10-29 14:57:56.331\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:57:56.424\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000043 is in DONE state\n",
      "\u001b[90m2025-10-29 14:57:56.435\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:57:56.440\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000044 is in DONE state\n",
      "Starting Iteration-14\n",
      "\u001b[90m2025-10-29 14:57:56.446\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:57:56.489\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000045 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (118.6).\n",
      "\u001b[90m2025-10-29 14:57:56.490\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:57:56.579\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000046 is in DONE state\n",
      "\u001b[90m2025-10-29 14:57:56.590\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:57:56.596\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000047 is in DONE state\n",
      "Starting Iteration-15\n",
      "\u001b[90m2025-10-29 14:57:56.601\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:57:56.654\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000048 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (129.0).\n",
      "\u001b[90m2025-10-29 14:57:56.655\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:57:56.749\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000049 is in DONE state\n",
      "\u001b[90m2025-10-29 14:57:56.759\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:57:56.765\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000050 is in DONE state\n",
      "Starting Iteration-16\n",
      "\u001b[90m2025-10-29 14:57:56.771\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:57:56.915\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000051 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (396.6).\n",
      "\u001b[90m2025-10-29 14:57:56.916\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:57:57.098\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000052 is in DONE state\n",
      "\u001b[90m2025-10-29 14:57:57.109\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:57:57.121\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000053 is in DONE state\n",
      "Starting Iteration-17\n",
      "\u001b[90m2025-10-29 14:57:57.121\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:57:57.171\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000054 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (102.0).\n",
      "\u001b[90m2025-10-29 14:57:57.172\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:57:57.263\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000055 is in DONE state\n",
      "\u001b[90m2025-10-29 14:57:57.274\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:57:57.280\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000056 is in DONE state\n",
      "Starting Iteration-18\n",
      "\u001b[90m2025-10-29 14:57:57.285\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:57:57.429\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000057 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (354.4).\n",
      "\u001b[90m2025-10-29 14:57:57.430\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:57:57.576\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000058 is in DONE state\n",
      "\u001b[90m2025-10-29 14:57:57.587\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:57:57.593\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000059 is in DONE state\n",
      "Starting Iteration-19\n",
      "\u001b[90m2025-10-29 14:57:57.598\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:57:57.661\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000060 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (171.4).\n",
      "\u001b[90m2025-10-29 14:57:57.662\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:57:57.827\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000061 is in DONE state\n",
      "\u001b[90m2025-10-29 14:57:57.838\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:57:57.846\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000062 is in DONE state\n",
      "Starting Iteration-20\n",
      "\u001b[90m2025-10-29 14:57:57.849\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:57:57.927\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000063 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (154.8).\n",
      "\u001b[90m2025-10-29 14:57:57.928\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:57:58.059\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000064 is in DONE state\n",
      "\u001b[90m2025-10-29 14:57:58.070\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:57:58.077\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000065 is in DONE state\n",
      "Starting Iteration-21\n",
      "\u001b[90m2025-10-29 14:57:58.081\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:57:58.165\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000066 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (230.2).\n",
      "\u001b[90m2025-10-29 14:57:58.165\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:57:58.380\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000067 is in DONE state\n",
      "\u001b[90m2025-10-29 14:57:58.391\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:57:58.403\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000068 is in DONE state\n",
      "Starting Iteration-22\n",
      "\u001b[90m2025-10-29 14:57:58.403\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:57:58.470\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000069 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (184.4).\n",
      "\u001b[90m2025-10-29 14:57:58.470\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:57:58.643\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000070 is in DONE state\n",
      "\u001b[90m2025-10-29 14:57:58.654\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:57:58.661\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000071 is in DONE state\n",
      "Starting Iteration-23\n",
      "\u001b[90m2025-10-29 14:57:58.665\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:57:58.760\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000072 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (207.0).\n",
      "\u001b[90m2025-10-29 14:57:58.761\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:57:58.989\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000073 is in DONE state\n",
      "\u001b[90m2025-10-29 14:57:59.000\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:57:59.012\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000074 is in DONE state\n",
      "Starting Iteration-24\n",
      "\u001b[90m2025-10-29 14:57:59.013\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:57:59.141\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000075 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (332.2).\n",
      "\u001b[90m2025-10-29 14:57:59.142\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:57:59.399\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000076 is in DONE state\n",
      "\u001b[90m2025-10-29 14:57:59.410\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:57:59.424\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000077 is in DONE state\n",
      "Starting Iteration-25\n",
      "\u001b[90m2025-10-29 14:57:59.425\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:57:59.492\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000078 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (142.6).\n",
      "\u001b[90m2025-10-29 14:57:59.493\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:57:59.646\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000079 is in DONE state\n",
      "\u001b[90m2025-10-29 14:57:59.657\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:57:59.664\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000080 is in DONE state\n",
      "Starting Iteration-26\n",
      "\u001b[90m2025-10-29 14:57:59.668\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:57:59.806\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000081 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (379.2).\n",
      "\u001b[90m2025-10-29 14:57:59.807\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:58:00.137\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000082 is in DONE state\n",
      "\u001b[90m2025-10-29 14:58:00.148\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:58:00.163\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000083 is in DONE state\n",
      "Starting Iteration-27\n",
      "\u001b[90m2025-10-29 14:58:00.164\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:58:00.295\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000084 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (350.6).\n",
      "\u001b[90m2025-10-29 14:58:00.296\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:58:00.603\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000085 is in DONE state\n",
      "\u001b[90m2025-10-29 14:58:00.614\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:58:00.622\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000086 is in DONE state\n",
      "Starting Iteration-28\n",
      "\u001b[90m2025-10-29 14:58:00.625\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:58:00.801\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000087 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (474.2).\n",
      "\u001b[90m2025-10-29 14:58:00.802\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:58:01.146\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000088 is in DONE state\n",
      "\u001b[90m2025-10-29 14:58:01.157\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:58:01.169\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000089 is in DONE state\n",
      "Starting Iteration-29\n",
      "\u001b[90m2025-10-29 14:58:01.170\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:58:01.242\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000090 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (187.0).\n",
      "\u001b[90m2025-10-29 14:58:01.243\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:58:01.515\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000091 is in DONE state\n",
      "\u001b[90m2025-10-29 14:58:01.525\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:58:01.533\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000092 is in DONE state\n",
      "Starting Iteration-30\n",
      "\u001b[90m2025-10-29 14:58:01.536\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:58:01.698\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000093 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (428.6).\n",
      "\u001b[90m2025-10-29 14:58:01.699\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:58:02.084\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000094 is in DONE state\n",
      "\u001b[90m2025-10-29 14:58:02.095\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:58:02.109\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000095 is in DONE state\n",
      "Starting Iteration-31\n",
      "\u001b[90m2025-10-29 14:58:02.110\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:58:02.190\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000096 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (179.6).\n",
      "\u001b[90m2025-10-29 14:58:02.191\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:58:02.479\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000097 is in DONE state\n",
      "\u001b[90m2025-10-29 14:58:02.490\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:58:02.499\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000098 is in DONE state\n",
      "Starting Iteration-32\n",
      "\u001b[90m2025-10-29 14:58:02.501\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:58:02.648\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000099 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (424.2).\n",
      "\u001b[90m2025-10-29 14:58:02.649\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:58:02.987\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000100 is in DONE state\n",
      "\u001b[90m2025-10-29 14:58:02.998\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:58:03.009\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000101 is in DONE state\n",
      "Starting Iteration-33\n",
      "\u001b[90m2025-10-29 14:58:03.010\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:58:03.129\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000102 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (345.8).\n",
      "\u001b[90m2025-10-29 14:58:03.130\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:58:03.494\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000103 is in DONE state\n",
      "\u001b[90m2025-10-29 14:58:03.505\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:58:03.520\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000104 is in DONE state\n",
      "Starting Iteration-34\n",
      "\u001b[90m2025-10-29 14:58:03.521\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:58:03.603\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000105 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (191.6).\n",
      "\u001b[90m2025-10-29 14:58:03.604\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:58:03.932\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000106 is in DONE state\n",
      "\u001b[90m2025-10-29 14:58:03.943\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:58:03.951\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000107 is in DONE state\n",
      "Starting Iteration-35\n",
      "\u001b[90m2025-10-29 14:58:03.954\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:58:04.074\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000108 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is not met yet (344.0).\n",
      "\u001b[90m2025-10-29 14:58:04.074\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['environment'] for execution\n",
      "\u001b[90m2025-10-29 14:58:04.389\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000109 is in DONE state\n",
      "\u001b[90m2025-10-29 14:58:04.400\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['update'] for execution\n",
      "\u001b[90m2025-10-29 14:58:04.417\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000110 is in DONE state\n",
      "Starting Iteration-36\n",
      "\u001b[90m2025-10-29 14:58:04.418\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['check_reward'] for execution\n",
      "\u001b[90m2025-10-29 14:58:04.596\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000111 is in DONE state\n",
      "stop criterion metric: MODEL_REWARD is met with value of: 490.2 . Breaking the active learning loop\n",
      "\u001b[90m2025-10-29 14:58:04.597\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[main]\u001b[0m │ Reinforcement Learning completed!\n",
      "\u001b[90m2025-10-29 14:58:04.597\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Initiating shutdown\n",
      "\u001b[90m2025-10-29 14:58:04.597\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[execution.backend(concurrent)]\u001b[0m │ Concurrent execution backend shutdown complete\n",
      "\u001b[90m2025-10-29 14:58:04.597\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Shutdown completed for all components.\n"
     ]
    }
   ],
   "source": [
    "async def run(rl, **kwargs):\n",
    "\n",
    "    # ========================================================================\n",
    "    # 0. HELPER FUNCTIONS\n",
    "    # ========================================================================\n",
    "    def discount_reward(rewards: List[float], gamma: float) -> List[float]:\n",
    "        g = 0.0\n",
    "        out = []\n",
    "        for r in reversed(rewards):\n",
    "            g = r + gamma * g\n",
    "            out.append(g)\n",
    "        return list(reversed(out))\n",
    "    def run_episode(env, policy: Network, seed: int = None) -> Tuple[List[np.ndarray], List[int], List[float]]:\n",
    "        obs, _ = env.reset(seed=seed)\n",
    "\n",
    "        obs_list, act_list, rew_list = [], [], []\n",
    "        done = False\n",
    "        while not done:\n",
    "            dist = policy.action_dist(np.expand_dims(obs, axis=0))\n",
    "            action = dist.sample().item()\n",
    "            obs_list.append(obs.copy())\n",
    "            act_list.append(action)\n",
    "\n",
    "            next_obs, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            rew_list.append(float(reward))\n",
    "            obs = next_obs\n",
    "        return obs_list, act_list, rew_list\n",
    "        \n",
    "    # ========================================================================\n",
    "    # 1. ENVIRONMENT TASK\n",
    "    # ========================================================================\n",
    "    @rl.environment_task(as_executable=False)\n",
    "    async def environment(*args, **kwargs) -> dict:\n",
    "        env = gym.make(cfg.env_id)\n",
    "        obs_dim = env.observation_space.shape[0]\n",
    "        n_actions = env.action_space.n\n",
    "        policy = Network(obs_dim, cfg.hidden_size, n_actions)\n",
    "        try:\n",
    "            policy.load_state_dict(torch.load(cfg.model_path, map_location=\"cpu\"))\n",
    "        except:\n",
    "            torch.save(policy.state_dict(), cfg.model_path)\n",
    "        episode_buffer = []\n",
    "        for _ in range(cfg.batch_size):\n",
    "            obs, _ = env.reset()\n",
    "\n",
    "            observations, actions, rewards = run_episode(env, policy)\n",
    "            G = discount_reward(rewards, cfg.gamma)\n",
    "            for o, a, g in zip(observations, actions, G):\n",
    "                episode_buffer.append((o, a, g))\n",
    "        obs_batch = [t[0] for t in episode_buffer]\n",
    "        act_batch = [t[1] for t in episode_buffer]\n",
    "        ret_batch = [t[2] for t in episode_buffer]\n",
    "        return {\"observations\": obs_batch, \"actions\": act_batch, \"returns\": ret_batch}\n",
    "\n",
    "    # ========================================================================\n",
    "    # 2. UPDATE TASK\n",
    "    # ========================================================================\n",
    "    @rl.update_task(as_executable=False)\n",
    "    async def update(*args, **kwargs) -> dict:\n",
    "        data = args[0] if args else kwargs.get(\"data\", {})\n",
    "        env = gym.make(cfg.env_id)\n",
    "        obs_dim = env.observation_space.shape[0]\n",
    "        n_actions = env.action_space.n\n",
    "        policy = Network(obs_dim, cfg.hidden_size, n_actions)\n",
    "        policy.load_state_dict(torch.load(cfg.model_path, map_location=\"cpu\"))\n",
    "        optimizer = optim.Adam(policy.parameters(), lr=cfg.lr)\n",
    "        obs_batch = torch.tensor(np.array(data[\"observations\"]), dtype=torch.float32, device=cfg.device)\n",
    "        act_batch = torch.tensor(data[\"actions\"], dtype=torch.int64, device=cfg.device)\n",
    "        ret_batch = torch.tensor(data[\"returns\"], dtype=torch.float32, device=cfg.device)\n",
    "        ret_batch = (ret_batch - ret_batch.mean()) / (ret_batch.std() + 1e-8)\n",
    "\n",
    "        dists = policy.action_dist(obs_batch)\n",
    "        logp = dists.log_prob(act_batch)\n",
    "        loss = -(logp * ret_batch).mean()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(policy.parameters(), max_norm=5.0)\n",
    "        optimizer.step()\n",
    "        torch.save(policy.state_dict(), cfg.model_path)\n",
    "        return {\"loss\": loss.item()}\n",
    "\n",
    "    # ========================================================================\n",
    "    # 3. STOP CRITERION TASK\n",
    "    # ========================================================================\n",
    "    @rl.as_stop_criterion(metric_name='MODEL_REWARD', threshold=475, operator=GREATER_THAN_THRESHOLD, as_executable=False)\n",
    "    async def check_reward(*args, **kwargs):\n",
    "        env = gym.make(cfg.env_id)\n",
    "        obs_dim = env.observation_space.shape[0]\n",
    "        n_actions = env.action_space.n\n",
    "        policy = Network(obs_dim, cfg.hidden_size, n_actions)\n",
    "        policy.load_state_dict(torch.load(cfg.model_path, map_location=\"cpu\"))\n",
    "        policy.eval()\n",
    "        rewards = []\n",
    "        for _ in range(5):\n",
    "            obs, _ = env.reset()\n",
    "            done = False\n",
    "            it_reward = 0.0\n",
    "    \n",
    "            while not done:\n",
    "                with torch.no_grad():\n",
    "                    dist = policy.action_dist(np.expand_dims(obs, axis=0))\n",
    "                    action = torch.argmax(dist.probs).item() \n",
    "    \n",
    "                obs, reward, terminated, truncated, _ = env.step(action)\n",
    "                done = terminated or truncated\n",
    "                it_reward += float(reward)\n",
    "            rewards.append(it_reward)\n",
    "        avg_reward = float(np.mean(rewards))\n",
    "        return avg_reward\n",
    "\n",
    "    # Run\n",
    "    logger.info(\"Starting Reinforcement Learning with ROSE...\")\n",
    "    await rl.learn(**kwargs)\n",
    "    logger.info(\"Reinforcement Learning completed!\")\n",
    "\n",
    "try:\n",
    "    engine = await ConcurrentExecutionBackend(ProcessPoolExecutor())\n",
    "    asyncflow = await WorkflowEngine.create(engine)\n",
    "    rl = SequentialReinforcementLearner(asyncflow)\n",
    "\n",
    "    init_default_logger(logging.INFO)\n",
    "    await run(rl, max_iter=int(cfg.episodes/cfg.batch_size))\n",
    "except Exception as e:\n",
    "    print(f'Learner Failed with: {e}')\n",
    "finally:\n",
    "    await rl.shutdown()\n",
    "    logging.getLogger().handlers.clear()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
